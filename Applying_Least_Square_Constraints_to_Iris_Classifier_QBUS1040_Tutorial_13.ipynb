{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Applying Least Square Constraints to Iris Classifier - QBUS1040 - Tutorial 13",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anoshawott/Foundations-of-Business-Analytics-QBUS1040/blob/master/Applying_Least_Square_Constraints_to_Iris_Classifier_QBUS1040_Tutorial_13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpvpBhR2tPQA",
        "colab_type": "text"
      },
      "source": [
        "# Applying Least Square Constraints via a Pythonic Approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtsULKWmqQFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def gram_schmidt(a):\n",
        "    q = []\n",
        "    for i in range(len(a)):\n",
        "        #orthogonalization\n",
        "        q_tilde = a[i]\n",
        "        for j in range(len(q)):\n",
        "            q_tilde = q_tilde - np.inner(q[j], a[i])*q[j] \n",
        "        \n",
        "        #Test for dependence\n",
        "        if np.linalg.norm(q_tilde) <= 1e-6: # 1e-6 = 0.000001 \n",
        "            print(\"Vectors are linearly dependent.\")\n",
        "            print (\"GS algorithm terminates at iteration \", i+1)\n",
        "            return q\n",
        "        \n",
        "        #Normalization\n",
        "        else:\n",
        "            qi = q_tilde/np.linalg.norm(q_tilde)\n",
        "            q.append(qi)\n",
        "    # print(\"Vector are linearly independent.\")\n",
        "    return q\n",
        "\n",
        "def qr_fac(a_matrix):\n",
        "    A = np.transpose(a_matrix) # Gram-schmidt alg. takes ROWS as vectors\n",
        "    Q = np.array(gram_schmidt(A))\n",
        "    Q = np.transpose(Q) # Output of Gram-schmidt alg. also takes ROWS as vectors\n",
        "    R = np.matmul(np.transpose(Q), a_matrix) # R = Q^T A\n",
        "    return Q, R\n",
        "\n",
        "def back_sub(upper_mat, b):\n",
        "    n = len(b)\n",
        "    x = b\n",
        "    for i in reversed(range(n)): # reversed() uses the reversed roder: n-1,...,0\n",
        "        for j in range(i+1, n):  # update x[i] using x[i+1],...x[n-1]\n",
        "            x[i] = x[i] - upper_mat[i, j]*x[j]\n",
        "        x[i] = x[i]/upper_mat[i,i]\n",
        "    return x\n",
        "\n",
        "def SLE_QR(A, b): # Solve Ax=b\n",
        "    Q, R = qr_fac(A) # 1. compute A = QR\n",
        "    b_tilde = np.matmul(Q.T, b) # 2. compute Q^T b\n",
        "    x = back_sub(R, b_tilde) # 3. solve Rx = Q^T b using back substitution\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLIpKJ1CqQFG",
        "colab_type": "code",
        "outputId": "9ff44e57-b9c0-48e6-c2e1-3420faaf902a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        }
      },
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "iris = datasets.load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "N = len(y)  # no. of observations\n",
        "A = np.concatenate((np.ones((N,1)), X), axis = 1)\n",
        "print(A[:3, :])\n",
        "print('Original observed response/outcome:')\n",
        "print(y)\n",
        "\n",
        "y_vir = -np.ones(N)\n",
        "for i in range(100, N):\n",
        "    y_vir[i] = 1\n",
        "print('Transformed observations:')\n",
        "print(y_vir)\n",
        "\n",
        "theta = SLE_QR(A, y_vir)\n",
        "print('The model parameters are:', theta)\n",
        "\n",
        "print('Predicted response')\n",
        "y_confidence = np.matmul(A, theta)\n",
        "y_prediction = np.zeros(N)\n",
        "for i in range(N):\n",
        "    if y_confidence[i] >= 0:\n",
        "        y_prediction[i] = 1 # it is Iris Virginica\n",
        "    else:\n",
        "        y_prediction[i] = -1 # it is NOT Iris Virginica\n",
        "print(y_prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.  5.1 3.5 1.4 0.2]\n",
            " [1.  4.9 3.  1.4 0.2]\n",
            " [1.  4.7 3.2 1.3 0.2]]\n",
            "Original observed response/outcome:\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "Transformed observations:\n",
            "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.]\n",
            "The model parameters are: [-2.39056373 -0.09175217  0.40553677  0.00797582  1.10355865]\n",
            "Predicted response\n",
            "[-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1.\n",
            " -1. -1.  1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1. -1. -1. -1.  1. -1.\n",
            " -1. -1. -1. -1. -1.  1. -1. -1. -1. -1. -1. -1.  1.  1. -1. -1. -1. -1.\n",
            " -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1. -1.  1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  1.  1.  1.  1.  1.  1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "hDwAVAKqqQFJ",
        "colab_type": "code",
        "outputId": "d7270081-339b-4f64-d29a-06dbc032370d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "print('Original observation')\n",
        "print(y)\n",
        "\n",
        "# transformed observation\n",
        "# Iris Setosa, Iris Versicolour, Iris Virginica\n",
        "\n",
        "y_true = -np.ones((N, 3))\n",
        "for i in range(N):\n",
        "    y_true[i,y[i]] = 1\n",
        "# print(y_true)    \n",
        "\n",
        "theta_Set = SLE_QR(A, y_true[:,0])\n",
        "print('The model parameters for Iris Setosa are:', theta_Set)\n",
        "\n",
        "theta_Ver = SLE_QR(A, y_true[:,1])\n",
        "print('The model parameters for Iris Versicolour are:', theta_Ver)\n",
        "\n",
        "theta_Vir = SLE_QR(A, y_true[:,2])\n",
        "print('The model parameters for Iris Virginica are:', theta_Vir)\n",
        "\n",
        "# compute the confidence\n",
        "yhat_0 = np.matmul(A, theta_Set)\n",
        "yhat_1 = np.matmul(A, theta_Ver)\n",
        "yhat_2 = np.matmul(A, theta_Vir)\n",
        "\n",
        "print('The predicted response')\n",
        "y_pre = np.zeros(N)\n",
        "for i in range(N):\n",
        "    y_pre[i] = np.argmax([yhat_0[i], yhat_1[i], yhat_2[i]])\n",
        "print(y_pre)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original observation\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "The model parameters for Iris Setosa are: [-0.76355422  0.13205954  0.48569574 -0.44931423 -0.11494546]\n",
            "The model parameters for Iris Versicolour are: [ 2.15411795 -0.04030737 -0.89123252  0.44133841 -0.98861319]\n",
            "The model parameters for Iris Virginica are: [-2.39056373 -0.09175217  0.40553677  0.00797582  1.10355865]\n",
            "The predicted response\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 2. 2. 2. 1. 1. 1. 2. 1. 1. 1. 1. 2. 1. 1. 2. 2. 2. 1. 1. 1. 2. 1.\n",
            " 1. 1. 1. 2. 1. 2. 2. 1. 1. 1. 1. 1. 2. 2. 2. 1. 2. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 1.\n",
            " 2. 2. 1. 2. 2. 2. 2. 2. 2. 1. 2. 2. 2. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5CHZyqgqjaP",
        "colab_type": "text"
      },
      "source": [
        "# Problem 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTNUEVlFqnPR",
        "colab_type": "code",
        "outputId": "c3fb784d-47a1-4bd6-fed5-b73f913d3705",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(3)\n",
        "\n",
        "#data\n",
        "adj = 3\n",
        "A = np.random.rand(20, 10)*adj\n",
        "C = np.random.rand(5, 10)*adj\n",
        "b = np.random.rand(20)*adj\n",
        "d = np.random.rand(5)*adj\n",
        "print('Vector d:', d)\n",
        "X_temp1 = np.concatenate((np.matmul(A.T, A)*2, C.T), axis = 1) #[2A^T A, C^T]\n",
        "X_temp2 = np.concatenate((C, np.zeros((5,5))), axis = 1) # Concantenating column wise the use of axis 1, ==> [C, 0]\n",
        "X = np.concatenate((X_temp1, X_temp2))\n",
        "print('The dimension of X:', X.shape)\n",
        "b_tilde = np.concatenate((np.matmul(A.T, b)*2, d))\n",
        "# solve x_hat\n",
        "xz = SLE_QR(X, b_tilde) # xz = np.matmul(np.linalg.plnv(X), b_tilde)\n",
        "x_hat = xz[:10]\n",
        "print('x_hat:', x_hat)\n",
        "print('The norm of C x_hat - d:', np.linalg.norm(np.matmul(C, x_hat)-d))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vector d: [0.75579091 2.71203741 1.03655202 0.17061772 2.14466002]\n",
            "The dimension of X: (15, 15)\n",
            "x_hat: [ 1.3423133   0.65871908  0.45206628 -0.14822702 -0.78607847  0.29411349\n",
            " -1.24279277  0.64490493 -0.00189746  0.36724937]\n",
            "The norm of C x_hat - d: 1.3514971597900126e-10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVuCKtnZtCfq",
        "colab_type": "text"
      },
      "source": [
        "Since C x_hat - d is very small therefore we have x_hat equal d."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nzf4p08Nuews",
        "colab_type": "code",
        "outputId": "70a165b6-7c06-4fe9-8703-d466f039a0ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#Solve x_ln, min|[Cx-d]|\n",
        "x_ln = np.matmul(np.linalg.pinv(C), d)\n",
        "print('x_ln', x_ln)\n",
        "print('The norm of C x_ln - d:', np.linalg.norm(np.matmul(C, x_ln)-d))\n",
        "# solution quality\n",
        "print('The norm of A x_hat - b', np.linalg.norm(np.matmul(A, x_hat)-b)**2)\n",
        "print('The norm of A x_ln - b', np.linalg.norm(np.matmul(A, x_ln)-b)**2)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_ln [ 0.78338639  1.2311555   0.20470268  0.21662707 -0.41669869 -0.14028718\n",
            " -0.84761481  0.62484688  0.32777545 -0.08250814]\n",
            "The norm of C x_ln - d: 2.2011063963608236e-15\n",
            "The norm of A x_hat - b 36.09422993370259\n",
            "The norm of A x_ln - b 61.188667102585626\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}